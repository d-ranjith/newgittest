name: my-service
description: My GraphQL service
type: GRAPHQL

graphqlServiceConfig:
  url: https://my-graphql-endpoint.com
  authenticationType: APIKEY
  apiKey: ${env.HARNESS_GRAPHQL_API_KEY}

deploymentType: KUBERNETES
kubernetes:
  manifestType: HELM
  chartName: my-chart
  chartVersion: 1.0.0
  overrideValuesYaml: |
    image:
      repository: my-graphql-image
      tag: latest
    service:
      port: 8080
    replicaCount: 3


mutation {
  createWorkflow(
    workflow: {
      name: "My Workflow"
      applicationId: "abc123"
      workflowType: CLOUD_PROVIDER
      file: "{ contents of your workflow file }"
    }
    environmentId: "def456"
    serviceOverrideVariables: {
      overrideValues: true
      valuesOverride: "{ contents of your service overrides file }"
    }
    workflowOverrideVariables: {
      overrideValues: true
      valuesOverride: "{ contents of your workflow overrides file }"
    }
  ) {
    workflow {
      id
      name
      workflowType
    }
  }
}


mutation createPipeline {
  createPipeline(
    input: {
      name: "My Pipeline"
      applicationId: "my-application-id"
      pipelineType: CD
      workflowIds: ["my-workflow-id"]
      pipelineStages: [
        {
          stageName: "Deploy to Test",
          stageType: DEPLOY,
          serviceActionId: "my-service-action-id",
          targetSpec: {
            cloudProviderName: "kubernetes",
            namespace: "test"
          }
        },
        {
          stageName: "Deploy to Prod",
          stageType: DEPLOY,
          serviceActionId: "my-service-action-id",
          targetSpec: {
            cloudProviderName: "kubernetes",
            namespace: "prod"
          }
        }
      ]
    }
  ) {
    pipeline {
      id
      name
    }
  }
}




#!/bin/bash

# Fetch the new Jenkins Docker image and agent from OpenShift
oc login <OpenShift_URL> -u <username> -p $OPENSHIFT_PASSWORD
oc project <project_name>
oc import-image jenkins:latest --from=<openshift_repo>/jenkins:latest --confirm
oc import-image jenkins-agent-python:latest --from=<openshift_repo>/jenkins-agent-python:latest --confirm
oc import-image jenkins-agent-java:latest --from=<openshift_repo>/jenkins-agent-java:latest --confirm

# Start a Jenkins pod using the new image
oc new-app jenkins:latest

# Validate that the Jenkins pod is running
if oc get pod | grep -q "jenkins.*Running"; then
    echo "Jenkins is running"
else
    echo "Error: Jenkins is not running"
    exit 1
fi

# Run a Python build using the new agent
oc new-build --name=python-build --image-stream=python:latest --binary
oc start-build python-build --from-dir=. --follow

# Run a Java build using the new agent
oc new-build --name=java-build --image-stream=java:latest --binary
oc start-build java-build --from-dir=. --follow

export OPENSHIFT_PASSWORD=your_password


import os

def compare_files(dir1, dir2):
    differences = {}
    for filename in os.listdir(dir1):
        file1_path = os.path.join(dir1, filename)
        file2_path = os.path.join(dir2, filename)
        if os.path.isfile(file1_path) and os.path.isfile(file2_path):
            with open(file1_path) as file1, open(file2_path) as file2:
                lines1 = file1.readlines()
                lines2 = file2.readlines()
                if lines1 != lines2:
                    differences[filename] = [line for line in lines1 if line not in lines2]
    return differences

dir1 = "/path/to/dir1"
dir2 = "/path/to/dir2"
differences = compare_files(dir1, dir2)
print(differences)
-----


harness-charts/
├── environments/
│   ├── values.yaml
│   ├── prod.yaml
│   ├── stage.yaml
│   └── test.yaml
├── services/
│   ├── values.yaml
│   ├── db/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── deployment.yaml
│   │       ├── service.yaml
│   │       └── ...
│   ├── snowflake/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── deployment.yaml
│   │       ├── service.yaml
│   │       └── ...
│   ├── batch/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── job.yaml
│   │       ├── ...
│   └── ansible/
│       ├── Chart.yaml
│       ├── values.yaml
│       └── templates/
│           ├── deployment.yaml
│           ├── ...
├── workflows/
│   ├── values.yaml
│   ├── my_workflow/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── steps.yaml
│   │       ├── ...
│   ├── another_workflow/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── steps.yaml
│   │       ├── ...
│   └── ...
├── pipelines/
│   ├── values.yaml
│   ├── my_pipeline/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── stages.yaml
│   │       ├── ...
│   ├── another_pipeline/
│   │   ├── Chart.yaml
│   │   ├── values.yaml
│   │   └── templates/
│   │       ├── stages.yaml
│   │       ├── ...
│   └── ...
└── ...

harness-charts/
├── charts/
│   ├── snowflake/
│   │   ├── Chart.yaml
│   │   ├── templates/
│   │   │   ├── service.yaml
│   │   │   ├── workflow.yaml
│   │   │   ├── pipeline.yaml
│   │   ├── values.yaml
│   ├── database/
│   │   ├── Chart.yaml
│   │   ├── templates/
│   │   │   ├── service.yaml
│   │   │   ├── workflow.yaml
│   │   │   ├── pipeline.yaml
│   │   ├── values.yaml
├── environments/
│   ├── values.yaml
│   ├── dev.yaml
│   ├── test.yaml
│   ├── prod.yaml
├── values.yaml


The charts folder contains subfolders for each deployment type: snowflake and database. Each of these subfolders has a Chart.yaml file to define the chart metadata, a values.yaml file to define the default values for that deployment type, and a templates folder that contains the Kubernetes manifests for the services, workflows, and pipelines.

The environments folder contains YAML files for each environment, including a values.yaml file that defines the default values for all environments. The adopting user can override these default values by creating a separate YAML file for each environment (e.g., dev.yaml, test.yaml, prod.yaml) and specifying the overrides there.

Here's an example of what the snowflake/values.yaml file might look like for a contributor managing the Snowflake deployment type:

And here's an example of what the database/values.yaml file might look like for a contributor managing the database deployment type:
database:
  driver: "oracle.jdbc.driver.OracleDriver"
  url: "jdbc:oracle:thin:@//mydatabase.host.com:1521/ORCLCDB"
  username: "myuser"
  password: "mypassword"






# Override values for the DB service
helm upgrade --install db-service harness-charts/services/db -f my-db-values.yaml

# Override values for the "my_workflow" workflow
helm upgrade --install my-workflow harness-charts/workflows/my_workflow -f my-workflow-values.yaml

# Override values for the "my_pipeline" pipeline
helm upgrade --install my-pipeline harness-charts/pipelines/my_pipeline -f my-pipeline-values.yaml



charts/oracle/Chart.yaml

apiVersion: v2
name: oracle
description: Helm chart for deploying Oracle
version: 0.1.0

charts/oracle/values.yaml

database:
  driver: "oracle.jdbc.driver.OracleDriver"
  url: "jdbc:oracle:thin:@//mydatabase.host.com:1521/ORCLCDB"
  username: "myuser"
  password: "mypassword"

charts/oracle/templates/service.yaml

apiVersion: v1
kind: Service
metadata:
  name: oracle
spec:
  ports:
    - name: oracle
      port: 1521
  selector:
    app: oracle

charts/oracle/templates/workflow.yaml

apiVersion: harness.io/v1
kind: Workflow
metadata:
  name: oracle-workflow
  annotations:
    description: Workflow for deploying Oracle
spec:
  applicationId: {{ .Values.applicationId }}
  pipelineStages:
  - type: DEPLOY
    name: deploy-oracle
    deployStage:
      accountName: {{ .Values.accountName }}
      strategy: ROLLING
      overrideValuesYaml: |
        image:
          repository: my-artifactory-instance.com/my-organization/oracle-chart
          tag: {{ .Values.chartVersion }}
      clusters:
      - clusterName: {{ .Values.clusterName }}
  triggers:
  - type: MANUAL



charts/oracle/templates/pipeline.yaml

apiVersion: harness.io/v1
kind: Pipeline
metadata:
  name: oracle-pipeline
  annotations:
    description: Pipeline for deploying Oracle using Kubernetes and Helm
spec:
  applicationId: {{ .Values.applicationId }}
  pipelineStages:
  - type: DEPLOY
    name: deploy-oracle
    deployStage:
      accountName: {{ .Values.accountName }}
      strategy: ROLLING
      overrideValuesYaml: |
        image:
          repository: my-artifactory-instance.com/my-organization/oracle-chart
          tag: {{ .Values.chartVersion }}
      clusters:
      - clusterName: {{ .Values.clusterName }}
  - type: DEPLOY
    name: deploy-oracle-service
    deployStage:
      accountName: {{ .Values.accountName }}
      strategy: ROLLING
      overrides: |
        {
          "service": {
            "values": {
              "image": {
                "repository": "my-artifactory-instance.com/my-organization/oracle-service-chart",
                "tag": "{{ .Values.serviceChartVersion }}"
              }
            }
          }
        }
      clusters:
      - clusterName: {{ .Values.clusterName }}
  triggers:
  - type: MANUAL



---



const axios = require('axios');
const fs = require('fs');
const { promisify } = require('util');
const exec = promisify(require('child_process').exec);

async function main() {
  try {
    // Fetch JSON data containing the latest chart version number with name
    const { data } = await axios.get('https://my-api.com/latest-chart-version');
    const chartName = data.name;
    const chartVersion = data.version;

    // Checkout Bitbucket code matching the chart name
    const { stdout: repoPath } = await exec(`git clone git@bitbucket.org:my-org/${chartName}.git`);
    await exec(`cd ${repoPath} && git checkout ${chartVersion}`);

    // Upload data to Harness.io using the Drift API
    const serviceYaml = fs.readFileSync(`${repoPath}/helm/chart/oracle/templates/service.yaml`, 'utf8');
    const workflowYaml = fs.readFileSync(`${repoPath}/helm/chart/oracle/templates/workflow.yaml`, 'utf8');
    const pipelineYaml = fs.readFileSync(`${repoPath}/helm/chart/oracle/templates/pipeline.yaml`, 'utf8');
    const driftApiUrl = 'https://driftapi.harness.io/v1alpha1';
    const harnessAccountId = 'my-account-id';
    const harnessApiKey = 'my-api-key';
    const headers = {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${harnessApiKey}`,
    };
    const serviceResponse = await axios.post(`${driftApiUrl}/accounts/${harnessAccountId}/services`, {
      name: chartName,
      configAsYaml: serviceYaml,
    }, { headers });
    console.log('Service uploaded:', serviceResponse.data);

    const workflowResponse = await axios.post(`${driftApiUrl}/accounts/${harnessAccountId}/workflows`, {
      name: chartName,
      configAsYaml: workflowYaml,
    }, { headers });
    console.log('Workflow uploaded:', workflowResponse.data);

    const pipelineResponse = await axios.post(`${driftApiUrl}/accounts/${harnessAccountId}/pipelines`, {
      name: chartName,
      configAsYaml: pipelineYaml,
    }, { headers });
    console.log('Pipeline uploaded:', pipelineResponse.data);

  } catch (error) {
    console.error(error);
  }
}

main();


-----
# General configuration
namespace: oracle
image: my-registry/oracle:latest
replicas: 2

# Database configuration
db:
  type: oracle
  name: mydb
  host: db.example.com
  port: 1521
  user: myuser
  password: mypassword

# Service configuration
service:
  type: LoadBalancer
  port: 8080
  healthCheckPath: /health

# Environment specific configuration
environments:
  - name: dev
    db:
      name: mydb-dev
      user: myuser-dev
      password: mypassword-dev
  - name: qa
    db:
      name: mydb-qa
      user: myuser-qa
      password: mypassword-qa
  - name: prod
    db:
      name: mydb-prod
      user: myuser-prod
      password: mypassword-prod
      replicas: 3
      
      
----

# Snowflake service values
snowflake:
  image:
    repository: myorg/snowflake
    tag: v1.0.0
  port: 8080
  replicas: 2
  # Additional service-specific values go here

# Workflow values
workflow:
  name: my-workflow
  workflowType: CONTINUOUS_DELIVERY
  # Additional workflow-specific values go here

# Pipeline values
pipeline:
  name: my-pipeline
  trigger: MANUAL
  # Additional pipeline-specific values go here

# Common values for all components
global:
  environment: dev
  # Additional global values go here

====

# Default values for Harness charts.
# This is a YAML-formatted file.

global:
  namespace: "default"
  app_name: "my-app"
  app_env: "dev"

environments:
  - name: "dev"
    type: "KUBERNETES"
    namespace: "dev-namespace"
    label_selector: "env=dev"
    # Optional: Define the Kubernetes service account to use for the deployment.
    # service_account_name: ""

  - name: "test"
    type: "KUBERNETES"
    namespace: "test-namespace"
    label_selector: "env=test"
    # Optional: Define the Kubernetes service account to use for the deployment.
    # service_account_name: ""

  - name: "prod"
    type: "KUBERNETES"
    namespace: "prod-namespace"
    label_selector: "env=prod"
    # Optional: Define the Kubernetes service account to use for the deployment.
    # service_account_name: ""

services:
  - name: "my-service"
    chart: "snowflake"
    chart_version: "1.0.0"
    # Optional: Define any overrides to the chart values.
    values_file: "service-overrides.yaml"

workflows:
  - name: "my-workflow"
    service_name: "my-service"
    chart: "oracle"
    chart_version: "1.0.0"
    # Optional: Define any overrides to the chart values.
    values_file: "workflow-overrides.yaml"

pipelines:
  - name: "my-pipeline"
    workflow_name: "my-workflow"
    environments:
      - name: "dev"
      - name: "test"
      - name: "prod"
    # Optional: Define an approval step before promoting to the next environment.
    approval_step:
      type: "MANUAL"
      name: "my-approval-step"
      description: "Please approve the deployment to the next environment."
      approver_email: "user@example.com"


